{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad3ba50",
   "metadata": {},
   "source": [
    "# 1. テキストデータのTF-IDFベクトル化関数\n",
    "問題:\n",
    "複数の商品説明文（文字列のリスト）を受け取り、scikit-learn の TfidfVectorizer を使用して各文書をTF-IDFベクトルに変換する関数 vectorize_texts_tfidf(texts) を作成してください。\n",
    "ベクトル化の際には、一般的な日本語のストップワード（例: 「の」「です」「ます」など。簡単なリストで可）を除外し、トークン化は単語単位（スペース区切り、または簡易的な形態素解析ライブラリ利用を想定するが、ここでは簡易的にスペース区切りで良い）で行うこととします。\n",
    "戻り値は、TF-IDF行列（疎行列または密行列）と、使用したベクトライザのインスタンスとします。\n",
    "\n",
    "期待される動作例:\n",
    "\n",
    "```Python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 簡易的な日本語ストップワードリストの例\n",
    "japanese_stopwords = [\"の\", \"に\", \"は\", \"を\", \"た\", \"が\", \"で\", \"て\", \"と\", \"し\", \"れ\", \"さ\", \"ある\", \"いる\", \"も\", \"する\", \"から\", \"な\", \"こと\", \"として\", \"です\", \"ます\"]\n",
    "\n",
    "def vectorize_texts_tfidf(texts, stopwords=japanese_stopwords):\n",
    "    # ここに処理を記述\n",
    "    pass\n",
    "\n",
    "descriptions = [\n",
    "    \"高機能 な スマートフォン です\",\n",
    "    \"軽量 で 高性能 な ノートパソコン\",\n",
    "    \"この スマートフォン は 最新 です\"\n",
    "]\n",
    "tfidf_matrix, vectorizer = vectorize_texts_tfidf(descriptions)\n",
    "# tfidf_matrix は (文書数 x 特徴語数) の行列\n",
    "# vectorizer.get_feature_names_out() などで特徴語を確認できる\n",
    "```\n",
    "注: 実際にはjanomeやMeCabといった形態素解析ライブラリと組み合わせることが望ましいですが、テストの簡略化のため上記のような想定としています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6230dad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6093b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb6ac60d",
   "metadata": {},
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b5dec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8863fa9",
   "metadata": {},
   "source": [
    "# 2. 簡単な商品カテゴリ分類モデルの訓練と評価\n",
    "問題:\n",
    "商品名（文字列のリスト X_texts）とそれに対応するカテゴリラベル（文字列のリスト y_labels）が与えられます。\n",
    "これらのデータを用いて、以下の手順で簡単な商品カテゴリ分類モデルを訓練し、評価する関数 train_and_evaluate_classifier(X_texts, y_labels) を作成してください。\n",
    "\n",
    "TfidfVectorizer を用いて商品名をベクトル化します。\n",
    "データを訓練用とテスト用に分割します（例: 80%訓練、20%テスト）。\n",
    "scikit-learn の LogisticRegression （または NaiveBayes）を用いて分類モデルを訓練します。\n",
    "テストデータでモデルの正解率（accuracy）を計算し、返します。\n",
    "期待される動作例:\n",
    "\n",
    "```Python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression # または from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_and_evaluate_classifier(X_texts, y_labels):\n",
    "    # ここに処理を記述\n",
    "    pass\n",
    "\n",
    "# サンプルデータ\n",
    "X_texts = [\"最新 iPhone 15 Pro\", \"美味しいリンゴ 青森産\", \"高性能ノートパソコン XYZ\", \"オーガニックコットン Tシャツ\", \"格安 Android スマホ\"]\n",
    "y_labels = [\"スマートフォン\", \"食品\", \"PC\", \"衣類\", \"スマートフォン\"]\n",
    "\n",
    "accuracy = train_and_evaluate_classifier(X_texts, y_labels)\n",
    "# accuracy は 0.0 から 1.0 の間の数値\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600a597",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476615c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "262f1e03",
   "metadata": {},
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b6276",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9760707",
   "metadata": {},
   "source": [
    "# 3. コサイン類似度計算関数\n",
    "問題:\n",
    "2つの特徴ベクトル（NumPy配列）vec1 と vec2 を受け取り、それらのコサイン類似度を計算する関数 calculate_cosine_similarity(vec1, vec2) を作成してください。\n",
    "コサイン類似度は、ベクトルの内積をそれぞれのベクトルのL2ノルム（ユークリッドノルム）の積で割った値です。ゼロ除算が発生する場合は0を返すようにしてください。\n",
    "\n",
    "期待される動作例:\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "def calculate_cosine_similarity(vec1, vec2):\n",
    "    # ここに処理を記述\n",
    "    pass\n",
    "\n",
    "vec_a = np.array([1, 1, 0, 1, 0])\n",
    "vec_b = np.array([1, 0, 1, 1, 1])\n",
    "vec_c = np.array([0, 0, 0, 0, 0])\n",
    "\n",
    "similarity_ab = calculate_cosine_similarity(vec_a, vec_b) # 約0.577\n",
    "similarity_ac = calculate_cosine_similarity(vec_a, vec_c) # 0.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02aa50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61311f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85f874c8",
   "metadata": {},
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb608e3b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edb0fe3c",
   "metadata": {},
   "source": [
    "# 4. K-Meansクラスタリングの適用とクラスタ中心の取得\n",
    "問題:\n",
    "商品データ（各商品が複数の数値特徴を持つと仮定し、NumPy配列 X_features で与えられる）とクラスタ数 k を受け取り、scikit-learn の KMeans を用いてデータをクラスタリングする関数 perform_kmeans_clustering(X_features, k) を作成してください。\n",
    "この関数は、各データポイントが属するクラスタのラベル（配列）と、各クラスタの中心座標（配列）を返すものとします。\n",
    "\n",
    "期待される動作例:\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def perform_kmeans_clustering(X_features, k):\n",
    "    # ここに処理を記述\n",
    "    pass\n",
    "\n",
    "# サンプルデータ (商品数 x 特徴数)\n",
    "X_features = np.array([\n",
    "    [1, 2], [1.5, 1.8], [5, 8],\n",
    "    [8, 8], [1, 0.6], [9, 11]\n",
    "])\n",
    "k = 2\n",
    "cluster_labels, cluster_centers = perform_kmeans_clustering(X_features, k)\n",
    "# cluster_labels は各データ点がどのクラスタに属するかを示す配列 (例: [0, 0, 1, 1, 0, 1])\n",
    "# cluster_centers は各クラスタの中心座標を示す配列 (例: [[1.16, 1.46], [7.33, 9.0]])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b36083",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2cc140",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "944e9687",
   "metadata": {},
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c4009",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "733bf707",
   "metadata": {},
   "source": [
    "# 5. 混同行列からの評価指標計算関数\n",
    "問題:\n",
    "ある二値分類モデルのテスト結果として得られた混同行列（2x2のNumPy配列）が与えられます。この混同行列から、正解率（Accuracy）、適合率（Precision）、再現率（Recall）、F1スコアを計算する関数 calculate_metrics_from_confusion_matrix(cm) を作成してください。\n",
    "混同行列の形式は [[TN, FP], [FN, TP]] （TN: True Negative, FP: False Positive, FN: False Negative, TP: True Positive）とします。ゼロ除算が発生する場合は0を返すようにしてください。\n",
    "\n",
    "期待される動作例:\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics_from_confusion_matrix(cm):\n",
    "    # ここに処理を記述\n",
    "    pass\n",
    "\n",
    "# 例: TN=50, FP=10, FN=5, TP=100\n",
    "confusion_matrix = np.array([[50, 10], [5, 100]])\n",
    "metrics = calculate_metrics_from_confusion_matrix(confusion_matrix)\n",
    "# metrics は {'accuracy': accuracy_val, 'precision': precision_val, 'recall': recall_val, 'f1_score': f1_score_val} のような辞書\n",
    "# 期待値: accuracy 約0.909, precision 約0.909, recall 約0.952, f1_score 約0.930\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e0e3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520f868",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "045c95ae",
   "metadata": {},
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289e09d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b57273a2",
   "metadata": {},
   "source": [
    "# 6. 特徴量の標準化関数\n",
    "問題:\n",
    "数値特徴からなるデータセット（NumPy配列 X、各行がサンプル、各列が特徴量）を受け取り、各特徴量を標準化（平均0、標準偏差1にスケーリング）する関数 standardize_features(X) を作成してください。scikit-learn の StandardScaler を使用するか、NumPyで直接計算しても構いません。\n",
    "\n",
    "期待される動作例:\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import StandardScaler # 使っても良い\n",
    "\n",
    "def standardize_features(X):\n",
    "    # ここに処理を記述\n",
    "    pass\n",
    "\n",
    "X_original = np.array([[1, -1, 2],\n",
    "                       [2, 0, 0],\n",
    "                       [0, 1, -1]], dtype=float)\n",
    "X_standardized = standardize_features(X_original)\n",
    "# X_standardized の各列は平均がほぼ0、標準偏差がほぼ1になる\n",
    "# 例:\n",
    "# [[ 0.         -1.22474487  1.33630621]\n",
    "#  [ 1.22474487  0.         -0.26726124]\n",
    "#  [-1.22474487  1.22474487 -1.06904497]]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa394c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb132f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4a74dc4",
   "metadata": {},
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775dbcd6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfb1da0a",
   "metadata": {},
   "source": [
    "# 7. LightGBM/XGBoostの主要ハイパーパラメータ設定の理解\n",
    "問題:\n",
    "LightGBMまたはXGBoostのような勾配ブースティング木モデルにおいて、モデルの複雑さを制御し、過学習を抑制するために調整されることが多い主要なハイパーパラメータを3つ挙げ、それぞれのパラメータがモデルにどのような影響を与えるかを簡単に説明してください。そして、それらのパラメータを指定してモデルを初期化する（訓練は不要）簡単なPythonコードスニペットを lightgbm.LGBMClassifier または xgboost.XGBClassifier を用いて示してください。\n",
    "\n",
    "期待される説明とコード例:\n",
    "\n",
    "例として挙げるパラメータ:\n",
    "n_estimators (木の数): 増やすとモデルの表現力は上がるが、過学習しやすくなる。\n",
    "learning_rate (学習率): 小さいほど学習は慎重に進み、汎化性能が上がることがあるが、多くの木が必要になる。\n",
    "max_depth (木の深さ): 深いほど複雑な関係を学習できるが、過学習しやすくなる。\n",
    "（その他、num_leaves, min_child_samples, subsample, colsample_bytree なども候補）\n",
    "\n",
    "```Python\n",
    "# LightGBMの場合の例\n",
    "import lightgbm as lgb\n",
    "\n",
    "def initialize_lgbm_with_params(n_estimators, learning_rate, max_depth):\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42 # 再現性のため\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 使用例\n",
    "lgbm_model = initialize_lgbm_with_params(n_estimators=100, learning_rate=0.1, max_depth=5)\n",
    "print(lgbm_model.get_params())\n",
    "```\n",
    "\n",
    "注: この問題はコーディングそのものより、ハイパーパラメータの知識を問うものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeca64d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225974e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a05b8c7",
   "metadata": {},
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85bc3c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f8ca831",
   "metadata": {},
   "source": [
    "# 8. 不均衡データに対する簡易オーバーサンプリング関数\n",
    "問題:\n",
    "二値分類タスクにおいて、少数派クラスのデータが極端に少ない不均衡データセット（特徴量 X とラベル y、NumPy配列）が与えられたとします。少数派クラスのサンプルを単純に複製することでオーバーサンプリングを行う関数 simple_oversample(X, y) を作成してください。多数派クラスのサンプル数は変更せず、少数派クラスのサンプル数が多数派クラスのサンプル数と同じになるように複製するものとします。\n",
    "（imblearn ライブラリの RandomOverSampler のような高度なものではなく、基本的な動作を実装してください。）\n",
    "\n",
    "期待される動作例:\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def simple_oversample(X, y):\n",
    "    # ここに処理を記述\n",
    "    pass\n",
    "\n",
    "# サンプルデータ (特徴量は1次元で簡略化)\n",
    "X_imbalanced = np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]])\n",
    "y_imbalanced = np.array([0, 0, 1, 0, 0, 0, 1, 0, 0, 0]) # クラス1が少数派\n",
    "\n",
    "X_resampled, y_resampled = simple_oversample(X_imbalanced, y_imbalanced)\n",
    "# Counter(y_resampled) の結果、両クラスのサンプル数が等しくなる (この例ではクラス0が8件、クラス1が2件なので、クラス1を6件複製し合計16件、各8件)\n",
    "# X_resampled の形状と y_resampled の形状も確認\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4f638",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c652e89d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8daecb7b",
   "metadata": {},
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91098e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edea8435",
   "metadata": {},
   "source": [
    "# 9. 商品レビューの簡易感情分析（ポジネガ辞書利用）\n",
    "問題:\n",
    "商品レビューのテキストと、ポジティブ単語のセット positive_words、ネガティブ単語のセット negative_words を受け取り、レビューの感情スコアを計算する関数 calculate_sentiment_score(review_text, positive_words, negative_words) を作成してください。\n",
    "スコアは「レビューに含まれるポジティブ単語の数 - レビューに含まれるネガティブ単語の数」とします。単語のカウントは単純な出現回数とし、大文字・小文字は区別しないものとします。\n",
    "\n",
    "期待される動作例:\n",
    "\n",
    "```Python\n",
    "def calculate_sentiment_score(review_text, positive_words, negative_words):\n",
    "    # ここに処理を記述\n",
    "    pass\n",
    "\n",
    "positive_set = {\"良い\", \"素晴らしい\", \"満足\", \"最高\", \"便利\"}\n",
    "negative_set = {\"悪い\", \"残念\", \"不満\", \"ひどい\", \"壊れた\"}\n",
    "\n",
    "review1 = \"この商品はとても良い。素晴らしい！\"\n",
    "score1 = calculate_sentiment_score(review1, positive_set, negative_set) # 期待値: 2 (良い, 素晴らしい)\n",
    "\n",
    "review2 = \"期待外れで残念。少し悪い点もある。\"\n",
    "score2 = calculate_sentiment_score(review2, positive_set, negative_set) # 期待値: -2 (残念, 悪い)\n",
    "\n",
    "review3 = \"特にコメントなし。\"\n",
    "score3 = calculate_sentiment_score(review3, positive_set, negative_set) # 期待値: 0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9374b60",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e012fa8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bed5387e",
   "metadata": {},
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485fe94",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a1f4306",
   "metadata": {},
   "source": [
    "# 10. 時系列データからの移動平均計算関数\n",
    "問題:\n",
    "商品の売上データなどの時系列データ（数値のリストまたはNumPy配列 series）と、ウィンドウサイズ window_size を受け取り、移動平均を計算してリストまたはNumPy配列で返す関数 calculate_moving_average(series, window_size) を作成してください。\n",
    "計算結果の配列の長さは、元の時系列データから window_size - 1 を引いたものになります（ウィンドウ内のデータが揃わない先頭部分は計算しない）。\n",
    "\n",
    "期待される動作例:\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "def calculate_moving_average(series, window_size):\n",
    "    # ここに処理を記述\n",
    "    pass\n",
    "\n",
    "sales_data = np.array([10, 12, 11, 15, 16, 14, 18, 20, 19, 22])\n",
    "window = 3\n",
    "moving_avg = calculate_moving_average(sales_data, window)\n",
    "# 期待される出力 (numpy array): [11.        , 12.66666667, 14.        , 15.        , 16.        , 17.33333333, 19.        , 20.33333333]\n",
    "# ( (10+12+11)/3, (12+11+15)/3, ... )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa751b4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b33d0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f901228",
   "metadata": {},
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9726106",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
